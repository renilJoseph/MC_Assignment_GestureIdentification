{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MC_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renilJoseph/MC_Assignment_Project/blob/master/MC_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU0uMy67eoTm",
        "colab_type": "text"
      },
      "source": [
        "# MC Project EEG data classifier\n",
        "\n",
        "**Objective** : In this notebook we will be training a Neural Network model that will predict the user given their eeg data. \n",
        "\n",
        "\n",
        "Here we have the data for 106 subjects with 3 recordings each. Each recording is 2 minutes long and the sensor is capturing data at a frequency of 160Hz. So each recording is a vector of size 19200. Since our data is temporal and can be visualized as a sequence we can use a convolutional neural network. Traditionally CNNs are used for image classification tasks, where it is able to \n",
        "figure out spatial relationships between pixels.\n",
        "\n",
        "More recently CNNs are starting to be used with time series data as well, where they are showing to be very successfull. LSTMs and RNNs are the class of neural networks that are commonly used for temporal data. When we tried our model with LSTM model it have very poor results (<10 % accuracy). CNNs aldo have the added advantage that they can be easily ported to mobiles, as Tensorflow currently does not support exporting LSTM or RNNs to mobile.\n",
        "\n",
        "**Note**: Currently we do not have any test or validation set since we have very\n",
        "few data. Once we had a few more data, it is recommended to use a validation set and test set.\n",
        "\n",
        "**Pre-requisites**\n",
        "\n",
        "* Scipy [for loading Matlab file]\n",
        "* Numpy [for numerical computaion]\n",
        "* Keras - tensorflow [for neural network]\n",
        "\n",
        "*Authors* : Krishna Babuji, Renil Joseph, Leroy Jacob Vargis, Gopikrishnan Ravindran Nair\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gBGmPoYixIB",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Here we will import all the necessary libraries for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkSG7EDc7Pj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUkVUHs8jCe1",
        "colab_type": "text"
      },
      "source": [
        "Next  let's download the dataset if it's not already present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1vbAvBqeCNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -Nq 'https://raw.githubusercontent.com/renilJoseph/MC_Assignment_Project/master/project/EEGDataset1.mat'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t20jPm6wjMqz",
        "colab_type": "text"
      },
      "source": [
        "Once we have the data we will transform the data into a pandas dataframe for ease of use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GRl6DL6eaBz",
        "colab_type": "code",
        "outputId": "706e1fbe-41b1-4027-a307-e84659ae9579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "mat = scipy.io.loadmat('EEGDataset1.mat')\n",
        "print(f'Mat shape : {mat[\"Raw_Data\"].shape}')\n",
        "\n",
        "eeg_df1 = pd.DataFrame(mat['Raw_Data'][:, 0, :])\n",
        "eeg_df1['id'] = eeg_df1.index\n",
        "eeg_df2 = pd.DataFrame(mat['Raw_Data'][:, 1, :])\n",
        "eeg_df2['id'] = eeg_df2.index\n",
        "eeg_df3 = pd.DataFrame(mat['Raw_Data'][:, 2, :])\n",
        "eeg_df3['id'] = eeg_df3.index\n",
        "\n",
        "eeg_df = pd.concat([eeg_df1, eeg_df2, eeg_df3], ignore_index=True)\n",
        "print(f'eeg_df shape : {eeg_df.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mat shape : (106, 3, 19200)\n",
            "eeg_df shape : (318, 19201)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xSKZbwjjbh0",
        "colab_type": "text"
      },
      "source": [
        "Here we can see that each vector is 19201 long(with the additional Id column).\n",
        "A reasonable assumption to make is that our predictions won't change much if we change the sampling rate from 160Hz to 80 Hz. Reducing the sampling rate will mean that our LSTM need not handle such a long vector. \n",
        "\n",
        "Another option that we have yet to try is just use the first half of the vector, that is use the full sixty seconds with 160 Hz instead of the 120 seconds with 80Hz. But the key idea here is to reduce the dimensions without loosing too much data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cghxBKKFXrjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Down sample from 120Hz to 60Hz\n",
        "col_drops = [ x for x in eeg_df.columns if x != 'id' and int(x)%2 ==1 ]\n",
        "eeg_df.drop(col_drops, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO2PGMloAkQF",
        "colab_type": "code",
        "outputId": "af871f30-2ede-48a9-bdb5-28e99ba7e60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, y_train = eeg_df.drop(['id'], axis=1), eeg_df['id']\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "#X_train = normalize(X_train, axis=0, order=2)\n",
        "y_train = to_categorical(y_train)\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(318, 9600, 1) (318, 106)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m87UlGTSlAxD",
        "colab_type": "text"
      },
      "source": [
        "#Model Definition & Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MCYrjC9lLQi",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of the model is not impressive, but we can see that it is better than  a naive model which is random guessing which would be at ~0.01.\n",
        "\n",
        "If we had more EEG data for these same users we could have created a validation set and tried to tune the hyperparameters more. Since we have only 3 recordings per user, it does not make much sense to create a train and validation set. \n",
        "\n",
        "Let's save this model for our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM8uVK97K4Xa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "19d9469f-8590-4311-afb0-34ec7dcf4ef0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(9600,1)))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(106, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print('Train...')\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=32, shuffle=True, epochs=7)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 318 samples\n",
            "Epoch 1/7\n",
            "318/318 [==============================] - 11s 34ms/sample - loss: 436.9851 - acc: 0.0189\n",
            "Epoch 2/7\n",
            "318/318 [==============================] - 10s 33ms/sample - loss: 46.1789 - acc: 0.1038\n",
            "Epoch 3/7\n",
            "318/318 [==============================] - 10s 33ms/sample - loss: 5.8665 - acc: 0.1226\n",
            "Epoch 4/7\n",
            "318/318 [==============================] - 11s 33ms/sample - loss: 4.2817 - acc: 0.2453\n",
            "Epoch 5/7\n",
            "318/318 [==============================] - 11s 33ms/sample - loss: 4.1024 - acc: 0.3836\n",
            "Epoch 6/7\n",
            "318/318 [==============================] - 11s 33ms/sample - loss: 3.6798 - acc: 0.5535\n",
            "Epoch 7/7\n",
            "318/318 [==============================] - 11s 34ms/sample - loss: 2.6620 - acc: 0.6981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f277264b7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLd1DCWzkH6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cnn_eeg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_NwE22hD7uM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "54073309-5879-4300-9b6e-cffb8b4f4862"
      },
      "source": [
        "!toco \\\n",
        "  --output_file=cnn_eeg.tflite\\\n",
        "  --keras_model_file=cnn_eeg.h5"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1206 03:24:54.882520 140497785186176 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1206 03:24:54.882921 140497785186176 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1206 03:24:54.985518 140497785186176 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2019-12-06 03:24:55.194002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-06 03:24:55.195969: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2019-12-06 03:24:55.196035: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d19228994a35): /proc/driver/nvidia/version does not exist\n",
            "2019-12-06 03:24:55.202813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-12-06 03:24:55.203077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563518471f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-06 03:24:55.203113: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-06 03:24:57.368545: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2019-12-06 03:24:57.368755: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2019-12-06 03:24:57.376924: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
            "2019-12-06 03:24:57.376994: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
            "2019-12-06 03:24:57.377005: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
            "W1206 03:24:57.389204 140497785186176 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1206 03:24:57.389508 140497785186176 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "I1206 03:24:57.458868 140497785186176 graph_util_impl.py:334] Froze 8 variables.\n",
            "I1206 03:24:57.624924 140497785186176 graph_util_impl.py:394] Converted 8 variables to const ops.\n",
            "2019-12-06 03:24:57.629810: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2019-12-06 03:24:57.629968: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2019-12-06 03:24:57.937690: E tensorflow/core/grappler/grappler_item_builder.cc:656] Init node conv1d_2/kernel/Assign doesn't exist in graph\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlTilkAkNw6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}