{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MC_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renilJoseph/MC_Assignment_Project/blob/master/MC_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU0uMy67eoTm",
        "colab_type": "text"
      },
      "source": [
        "# MC Project EEG data classifier\n",
        "\n",
        "**Objective** : In this notebook we will be training a Neural Network model that will predict the user given their eeg data. \n",
        "\n",
        "\n",
        "Here we have the data for 106 subjects with 3 recordings each. Each recording is 2 minutes long and the sensor is capturing data at a frequency of 160Hz. So each recording is a vector of size 19200. Since our data is temporal and can be visualized as a sequence we can use a convolutional neural network. Traditionally CNNs are used for image classification tasks, where it is able to \n",
        "figure out spatial relationships between pixels.\n",
        "\n",
        "More recently CNNs are starting to be used with time series data as well, where they are showing to be very successfull. LSTMs and RNNs are the class of neural networks that are commonly used for temporal data. When we tried our model with LSTM model it have very poor results (<10 % accuracy). CNNs aldo have the added advantage that they can be easily ported to mobiles, as Tensorflow currently does not support exporting LSTM or RNNs to mobile.\n",
        "\n",
        "**Note**: Currently we do not have any test or validation set since we have very\n",
        "few data. Once we had a few more data, it is recommended to use a validation set and test set.\n",
        "\n",
        "**Pre-requisites**\n",
        "\n",
        "* Scipy [for loading Matlab file]\n",
        "* Numpy [for numerical computaion]\n",
        "* Keras - tensorflow [for neural network]\n",
        "\n",
        "*Authors* : Krishna Babuji, Renil Joseph, Leroy Jacob Vargis, Gopikrishnan Ravindran Nair\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gBGmPoYixIB",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Here we will import all the necessary libraries for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkSG7EDc7Pj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Flatten, LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUkVUHs8jCe1",
        "colab_type": "text"
      },
      "source": [
        "Next  let's download the dataset if it's not already present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1vbAvBqeCNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -Nq 'https://raw.githubusercontent.com/renilJoseph/MC_Assignment_Project/master/project/EEGDataset1.mat'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t20jPm6wjMqz",
        "colab_type": "text"
      },
      "source": [
        "Once we have the data we will transform the data into a pandas dataframe for ease of use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GRl6DL6eaBz",
        "colab_type": "code",
        "outputId": "bc9d2759-c5a8-4f67-b89d-243656156200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "mat = scipy.io.loadmat('EEGDataset1.mat')\n",
        "print(f'Mat shape : {mat[\"Raw_Data\"].shape}')\n",
        "\n",
        "eeg_df1 = pd.DataFrame(mat['Raw_Data'][:, 0, :])\n",
        "eeg_df1['id'] = eeg_df1.index\n",
        "eeg_df2 = pd.DataFrame(mat['Raw_Data'][:, 1, :])\n",
        "eeg_df2['id'] = eeg_df2.index\n",
        "eeg_df3 = pd.DataFrame(mat['Raw_Data'][:, 2, :])\n",
        "eeg_df3['id'] = eeg_df3.index\n",
        "\n",
        "eeg_df = pd.concat([eeg_df1, eeg_df2, eeg_df3], ignore_index=True)\n",
        "print(f'eeg_df shape : {eeg_df.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mat shape : (106, 3, 19200)\n",
            "eeg_df shape : (318, 19201)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xSKZbwjjbh0",
        "colab_type": "text"
      },
      "source": [
        "Here we can see that each vector is 19201 long(with the additional Id column).\n",
        "A reasonable assumption to make is that our predictions won't change much if we change the sampling rate from 160Hz to 80 Hz. Reducing the sampling rate will mean that our LSTM need not handle such a long vector. \n",
        "\n",
        "Another option that we have yet to try is just use the first half of the vector, that is use the full sixty seconds with 160 Hz instead of the 120 seconds with 80Hz. But the key idea here is to reduce the dimensions without loosing too much data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cghxBKKFXrjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Down sample from 120Hz to 60Hz\n",
        "col_drops = [ x for x in eeg_df.columns if x != 'id' and int(x)%2 ==1 ]\n",
        "eeg_df.drop(col_drops, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO2PGMloAkQF",
        "colab_type": "code",
        "outputId": "4ce275ad-530a-4fb0-baf2-617ed50e4c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, y_train = eeg_df.drop(['id'], axis=1), eeg_df['id']\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "#X_train = normalize(X_train, axis=0, order=2)\n",
        "y_train = to_categorical(y_train)\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(318, 9600, 1) (318, 106)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m87UlGTSlAxD",
        "colab_type": "text"
      },
      "source": [
        "#Model Definition & Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVw1PGBzVJY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "0a84eceb-7806-4783-a578-05ca1884b13b"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(9600,1)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(106, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print('Train...')\n",
        "\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, batch_size=64, shuffle=True, epochs=10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 106)               27242     \n",
            "=================================================================\n",
            "Total params: 60,778\n",
            "Trainable params: 60,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 318 samples\n",
            "Epoch 1/10\n",
            "318/318 [==============================] - 64s 200ms/sample - loss: 4.7158 - acc: 0.0126\n",
            "Epoch 2/10\n",
            "318/318 [==============================] - 61s 191ms/sample - loss: 4.6717 - acc: 0.0094\n",
            "Epoch 3/10\n",
            "318/318 [==============================] - 61s 190ms/sample - loss: 4.6069 - acc: 0.0063\n",
            "Epoch 4/10\n",
            "318/318 [==============================] - 61s 191ms/sample - loss: 4.5792 - acc: 0.0220\n",
            "Epoch 5/10\n",
            "318/318 [==============================] - 61s 191ms/sample - loss: 4.5495 - acc: 0.0189\n",
            "Epoch 6/10\n",
            "318/318 [==============================] - 60s 190ms/sample - loss: 4.5202 - acc: 0.0220\n",
            "Epoch 7/10\n",
            "318/318 [==============================] - 61s 193ms/sample - loss: 4.4878 - acc: 0.0346\n",
            "Epoch 8/10\n",
            "318/318 [==============================] - 61s 192ms/sample - loss: 4.4473 - acc: 0.0440\n",
            "Epoch 9/10\n",
            "318/318 [==============================] - 61s 192ms/sample - loss: 4.4197 - acc: 0.0377\n",
            "Epoch 10/10\n",
            "318/318 [==============================] - 61s 192ms/sample - loss: 4.3878 - acc: 0.0314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0689bbd2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_bO84DKDkdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('lstm_eeg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MCYrjC9lLQi",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of the model is not impressive, but we can see that it is better than  a naive model which is random guessing which would be at ~0.01.\n",
        "\n",
        "If we had more EEG data for these same users we could have created a validation set and tried to tune the hyperparameters more. Since we have only 3 recordings per user, it does not make much sense to create a train and validation set. \n",
        "\n",
        "Let's save this model for our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM8uVK97K4Xa",
        "colab_type": "code",
        "outputId": "f600a091-b491-4d67-95c5-e39a88b7dbe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(9600,1)))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(106, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print('Train...')\n",
        "\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, batch_size=64, shuffle=True, epochs=7)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 9598, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 9596, 32)          6176      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9596, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 4798, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 153536)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               39305472  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 106)               27242     \n",
            "=================================================================\n",
            "Total params: 39,339,146\n",
            "Trainable params: 39,339,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 318 samples\n",
            "Epoch 1/7\n",
            "318/318 [==============================] - 11s 34ms/sample - loss: 393.6662 - acc: 0.0126\n",
            "Epoch 2/7\n",
            "318/318 [==============================] - 10s 30ms/sample - loss: 222.6186 - acc: 0.0377\n",
            "Epoch 3/7\n",
            "318/318 [==============================] - 10s 30ms/sample - loss: 61.8287 - acc: 0.0881\n",
            "Epoch 4/7\n",
            "318/318 [==============================] - 10s 30ms/sample - loss: 13.9535 - acc: 0.1258\n",
            "Epoch 5/7\n",
            "318/318 [==============================] - 10s 30ms/sample - loss: 5.7774 - acc: 0.1824\n",
            "Epoch 6/7\n",
            "318/318 [==============================] - 9s 30ms/sample - loss: 3.3743 - acc: 0.4403\n",
            "Epoch 7/7\n",
            "318/318 [==============================] - 10s 30ms/sample - loss: 2.8116 - acc: 0.7704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0683169438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLd1DCWzkH6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cnn_eeg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_NwE22hD7uM",
        "colab_type": "code",
        "outputId": "2ace554c-21fe-4b8f-e6ec-47272ded2dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "!toco \\\n",
        "  --output_file=cnn_eeg.tflite\\\n",
        "  --keras_model_file=cnn_eeg.h5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1207 02:03:50.061067 139719327594368 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1207 02:03:50.061634 139719327594368 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1207 02:03:50.213816 139719327594368 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2019-12-07 02:03:50.558300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-07 02:03:50.561480: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2019-12-07 02:03:50.561541: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (29ee7749d242): /proc/driver/nvidia/version does not exist\n",
            "2019-12-07 02:03:50.659094: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-12-07 02:03:50.659424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603c43e1f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-07 02:03:50.659465: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-07 02:03:53.952692: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2019-12-07 02:03:53.952894: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2019-12-07 02:03:53.961999: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
            "2019-12-07 02:03:53.962074: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
            "2019-12-07 02:03:53.962085: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
            "W1207 02:03:53.977734 139719327594368 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1207 02:03:53.978034 139719327594368 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "I1207 02:03:54.053823 139719327594368 graph_util_impl.py:334] Froze 8 variables.\n",
            "I1207 02:03:54.220572 139719327594368 graph_util_impl.py:394] Converted 8 variables to const ops.\n",
            "2019-12-07 02:03:54.227994: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2019-12-07 02:03:54.228219: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2019-12-07 02:03:54.680741: E tensorflow/core/grappler/grappler_item_builder.cc:656] Init node conv1d/kernel/Assign doesn't exist in graph\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlTilkAkNw6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}